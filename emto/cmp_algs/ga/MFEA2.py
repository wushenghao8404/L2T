import numpy as np
from copy import deepcopy
import emto.evol_operator as eo
from scipy.optimize import fminbound

class MFEA2:
    '''
        Implementation of multifactorial evolutionary algorithm with version II
        Ref: @article{bali2019multifactorial,
                      title={Multifactorial evolutionary algorithm with online transfer parameter estimation: MFEA-II},
                      author={Bali, Kavitesh Kumar and Ong, Yew-Soon and Gupta, Abhishek and Tan, Puay Siew},
                      journal={IEEE Transactions on Evolutionary Computation},
                      volume={24},
                      number={1},
                      pages={69--83},
                      year={2019},
                      publisher={IEEE}
                     }

    '''

    def __init__(self, env):
        self.env = env
        self.tasks = None
        self.rmp_mat = np.full(shape=(self.env.n_tasks, self.env.n_tasks), fill_value=np.nan)

    def run(self, env_seed):
        _, env_info = self.env.reset(seed=env_seed)
        self.task_max_nfe = self.env.task_max_nfe
        self.rec_nfe = self.env.rec_nfe
        self.max_nfe = self.env.max_nfe
        self.nfe = 0
        self.task_ids = list(np.arange(self.env.n_tasks))

        for gen in range(self.env.max_gen):
            # print('gen',gen,'error',[task.get_error() for task in self.env.tasks])
            self.rmp_mat = learn_rmp([ev_proc.cur_pop for ev_proc in self.env.ev_procs], self.env.n_dims)

            offspring_pops = np.full(shape=(self.env.n_tasks, self.env.pop_size_per_task, self.env.n_dims), fill_value=np.nan)
            offspring_fits = np.full(shape=(self.env.n_tasks, self.env.pop_size_per_task), fill_value=np.nan)
            offspring_count = [0] * self.env.n_tasks

            parent_lpop = deepcopy(self.env.ev_procs[0].cur_pop)
            parent_task_ids = np.array([0] * self.env.pop_size_per_task)
            for task_id in range(1, self.env.n_tasks):
                parent_lpop = np.concatenate((parent_lpop, self.env.ev_procs[task_id].cur_pop))
                parent_task_ids = np.r_[parent_task_ids, np.array([task_id] * self.env.pop_size_per_task)]

            s_ = np.random.permutation(parent_lpop.shape[0])
            half_lpop_size = len(s_) // 2

            for i in range(half_lpop_size):
                i1 = s_[i]
                i2 = s_[i + half_lpop_size]
                p1_task_id = parent_task_ids[i1]  # serve as target task parent
                p2_task_id = parent_task_ids[i2]  # serve as source task parent

                if p1_task_id == p2_task_id:
                    # the target offsprings are generated by self evolution (i.e., SBX + polynomial mutate)
                    child1, child2 = eo.simulated_binary_crossover(parent_lpop[i1], parent_lpop[i2],
                                                                   yita_c=self.env.ev_procs[p1_task_id]._yita_c)
                    offspring_pops[p1_task_id][offspring_count[p1_task_id]] = \
                        eo.polynomial_mutation(child1, yita_m=self.env.ev_procs[p1_task_id]._yita_m)
                    offspring_count[p1_task_id] += 1
                    offspring_pops[p2_task_id][offspring_count[p2_task_id]] = \
                        eo.polynomial_mutation(child2, yita_m=self.env.ev_procs[p2_task_id]._yita_m)
                    offspring_count[p2_task_id] += 1
                elif np.random.rand() < self.rmp_mat[p1_task_id, p2_task_id]:
                    # inter-task knowledge transfer by SBX between individuls from two tasks, followed by mutation
                    child1, child2 = eo.simulated_binary_crossover(parent_lpop[i1], parent_lpop[i2],
                                                                   yita_c=self.env.ev_procs[p1_task_id]._yita_c)
                    offspring_pops[p1_task_id][offspring_count[p1_task_id]] = \
                        eo.polynomial_mutation(child1, yita_m=self.env.ev_procs[p1_task_id]._yita_m)
                    offspring_count[p1_task_id] += 1
                    offspring_pops[p2_task_id][offspring_count[p2_task_id]] = \
                        eo.polynomial_mutation(child2, yita_m=self.env.ev_procs[p2_task_id]._yita_m)
                    offspring_count[p2_task_id] += 1
                else:
                    # both the target and source offspring are generated by self evolution (i.e., polynomial mutate)
                    child1 = eo.polynomial_mutation(parent_lpop[i1], yita_m=self.env.ev_procs[p1_task_id]._yita_m)
                    offspring_pops[p1_task_id][offspring_count[p1_task_id]] = child1
                    offspring_count[p1_task_id] += 1
                    child2 = eo.polynomial_mutation(parent_lpop[i2], yita_m=self.env.ev_procs[p2_task_id]._yita_m)
                    offspring_pops[p2_task_id][offspring_count[p2_task_id]] = child2
                    offspring_count[p2_task_id] += 1

            assert (np.array(offspring_count) == self.env.pop_size_per_task).all(), \
                'The offspring count for all pops should be equal to pop size'

            for task_id in range(self.env.n_tasks):
                # clip the population to satisfy box constraint
                offspring_pops[task_id] = np.clip(offspring_pops[task_id], self.env.xlb, self.env.xub)

                # fitness evaluation
                offspring_fits[task_id] = self.env.tasks[task_id](offspring_pops[task_id])

                # update population by selection
                self.env.ev_procs[task_id].update(offspring_pops[task_id], offspring_fits[task_id])

        y_trajectory = []
        y_final = np.array([np.min(task._y_trajectory[:self.task_max_nfe]) - task.f.fopt for task in self.env.tasks])
        for task_id in range(self.env.n_tasks):
            task_y_trajectory = np.array(self.env.tasks[task_id]._y_trajectory) - self.env.tasks[task_id].f.fopt
            for i in range(1, len(task_y_trajectory)):
                task_y_trajectory[i] = np.min([task_y_trajectory[i], task_y_trajectory[i - 1]])
            y_trajectory.append(task_y_trajectory[:self.task_max_nfe:self.rec_nfe])
        y_trajectory = np.array(y_trajectory).T
        self.clean()
        return y_final, y_trajectory, env_info

    def clean(self):
        self.tasks = None


def loglik(rmp, pop_data, n_tasks):
    cp_popdata = deepcopy(pop_data)
    f = 0.0
    for i in range(2):
        for j in range(2):
            if i == j:
                cp_popdata[i][:, j] *= (1 - (0.5 * (n_tasks - 1) * rmp / n_tasks))
            else:
                cp_popdata[i][:, j] *= (0.5 * (n_tasks - 1) * rmp / n_tasks)
        f += np.sum(-np.log(np.sum(cp_popdata[i], axis=1)))
    return f


def learn_rmp(pops: list, dim):
    n_tasks = len((pops))
    rmp_mat = np.eye(n_tasks)
    prob_model = []
    for i in range(n_tasks):
        prob_model.append({})
        prob_model[i]['n_sample'] = pops[i].shape[0]
        rand_mat = np.random.rand(int(0.1 * prob_model[i]['n_sample']), dim)
        prob_model[i]['mean'] = np.mean(np.r_[pops[i],rand_mat], axis=0)
        prob_model[i]['std'] = np.std(np.r_[pops[i],rand_mat], axis=0)

    for i in range(n_tasks):
        for j in range(i+1, n_tasks):
            # print("begin calculate statistics")
            pop_data = [np.ones((prob_model[i]['n_sample'], 2)), np.ones((prob_model[j]['n_sample'], 2))]
            for k1 in range(prob_model[i]['n_sample']):
                for k2 in range(dim):
                    x = pops[i][k1, k2]
                    mu1 = prob_model[i]['mean'][k2]
                    sig1 = prob_model[i]['std'][k2]
                    mu2 = prob_model[j]['mean'][k2]
                    sig2 = prob_model[j]['std'][k2]
                    pop_data[0][k1, 0] *= 1 / (np.sqrt(2 * np.pi) * sig1) * np.exp(-(x - mu1) ** 2 / (2 * sig1 ** 2))
                    pop_data[0][k1, 1] *= 1 / (np.sqrt(2 * np.pi) * sig2) * np.exp(-(x - mu2) ** 2 / (2 * sig2 ** 2))

            for k1 in range(prob_model[j]['n_sample']):
                for k2 in range(dim):
                    x = pops[j][k1, k2]
                    mu1 = prob_model[i]['mean'][k2]
                    sig1 = prob_model[i]['std'][k2]
                    mu2 = prob_model[j]['mean'][k2]
                    sig2 = prob_model[j]['std'][k2]
                    pop_data[1][k1, 0] *= 1 / (np.sqrt(2 * np.pi) * sig1) * np.exp(-(x - mu1) ** 2 / (2 * sig1 ** 2))
                    pop_data[1][k1, 1] *= 1 / (np.sqrt(2 * np.pi) * sig2) * np.exp(-(x - mu2) ** 2 / (2 * sig2 ** 2))

            # print("begin optimize loglikehood")
            def rmploglik(rmp):
                return loglik(rmp, pop_data=pop_data, n_tasks=n_tasks)

            rmp_mat[i, j] = np.clip(fminbound(rmploglik, 0, 1) + np.random.normal(0, 0.01),0.0,1.0)
            rmp_mat[j, i] = rmp_mat[i, j]
    # print(rmp_mat)
    return rmp_mat


if __name__ == '__main__':
    import emto
    import gymnasium as gym

    env = gym.make('l2t_emto-v5', problem_name='bbob-v1')
    algo = MFEA2(env)
    for env_seed in range(2):
        print(algo.run(env_seed))

